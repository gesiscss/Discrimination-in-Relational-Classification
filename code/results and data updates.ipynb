{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from joblib import Parallel\n",
    "from joblib import delayed\n",
    "from utils import io\n",
    "from utils import estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 1, 13)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = \"BAH-N2000-m20-B0.3-H0.9-i3-x5-h0.9-k39.6-km36.5-kM40.9_nodes\" # 11\n",
    "s2 = \"Caltech36_nodes\" # 1\n",
    "s3 = \"BAH-Caltech36-N701-m2-B0.33-Hmm0.63-HMM0.44-i1-x5-h0.5-k4.0-km5.0-kM3.5_nodes\" # 13\n",
    "len(s1.split(\"-\")), len(s2.split(\"-\")), len(s3.split(\"-\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BAH-Swarthmore42-N1519-m2-B0.49',\n",
       " 'mm0.54',\n",
       " 'MM0.51-i1-x5-h0.5-k4.0-km4.1-kM3.9_nodes']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#s = 'BAH-Swarthmore42-N1519-m2-B0.49-Hmm0.54-HMM0.51-i1-x5-h0.5-k4.0-km4.1-kM3.9_nodes' #3\n",
    "#s = 'BAH-N2000-m20-B0.1-H0.0-i1-x5-h0.0-k37.9-km189.4-kM21.0.gpickle' #2\n",
    "#s = 'Swarthmore42.gpickle' # 1\n",
    "s.split('-H')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _change_empirical_graph(fn):\n",
    "    g = io.load_gpickle(fn)  \n",
    "    \n",
    "    h = round(np.mean([g.graph['HMM'], g.graph['Hmm']]),2)\n",
    "    if h != g.graph['H']:\n",
    "        g.graph['H'] = h\n",
    "        print(g.graph)\n",
    "        io.write_gpickle(g, fn)\n",
    "        return 1\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def _change_fit_graph(fn):\n",
    "    df = io.load_csv('../results-batch/summary_datasets.csv')\n",
    "    \n",
    "    g = io.load_gpickle(fn)  \n",
    "    \n",
    "    if 'H' in g.graph:\n",
    "        dataset = g.graph['fullname']\n",
    "        \n",
    "        if g.graph['name'] == 'Sex':\n",
    "            g.graph['name'] = 'Escorts'\n",
    "            \n",
    "        if 'Hmm' not in g.graph:\n",
    "            tmp = df.query(\"dataset==@dataset\").copy()\n",
    "            g.graph['Hmm'] = tmp.Hmm.iloc[0]\n",
    "            g.graph['HMM'] = tmp.HMM.iloc[0]\n",
    "            g.graph['H'] = round(np.mean([tmp.Hmm.iloc[0],tmp.HMM.iloc[0]]),2)\n",
    "            \n",
    "            try:\n",
    "                #print(g.graph['name'])\n",
    "                #io.write_gpickle(g, fn)\n",
    "                return 1\n",
    "            except:\n",
    "                return -1\n",
    "        else:\n",
    "            return None\n",
    "    else:\n",
    "        return -2\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def _change_synthetic_graph(fn):\n",
    "    g=io.load_gpickle(fn)  \n",
    "    if 'H' in g.graph:\n",
    "        try:\n",
    "            _ = float(g.graph['H'])\n",
    "            return None\n",
    "        except:\n",
    "            if g.graph['H'].startswith('MM') and 'Hmm' in g.graph and 'HMM' in g.graph:\n",
    "                g.graph['H'] = round(np.mean([g.graph['Hmm'], g.graph['HMM']]),2)\n",
    "                try:\n",
    "                    #io.write_gpickle(g, fn)\n",
    "                    return 1\n",
    "                except:\n",
    "                    return -1\n",
    "    return 0\n",
    "\n",
    "def _change_empirical_eval(fn):\n",
    "    df = io.load_csv('../results-batch/summary_datasets.csv')\n",
    "    obj = io.load_pickle(fn, verbose=False)\n",
    "    #/bigdata/lespin/Network-Unbiased-Inference/results/Caltech36_nodes/P20_evaluation_10.pickle\n",
    "    \n",
    "    dataset = fn.split(\"/\")[-2].replace('_nodes','')\n",
    "    tmp = df.query(\"dataset==@dataset\").copy()\n",
    "    h = round(np.mean([tmp.Hmm.iloc[0], tmp.HMM.iloc[0]]),2)\n",
    "    \n",
    "    if h != obj['H']:\n",
    "        obj['Hmm'] = tmp.Hmm.iloc[0]\n",
    "        obj['HMM'] = tmp.HMM.iloc[0]\n",
    "        obj['H'] = h\n",
    "        \n",
    "        try:\n",
    "            #io.write_pickle(obj, fn)\n",
    "            return 1\n",
    "        except:\n",
    "            return -1\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "    return 0\n",
    "    \n",
    "def _change_synthetic_eval(fn):\n",
    "    obj = io.load_pickle(fn, verbose=False)\n",
    "         \n",
    "    if 'H' in obj:\n",
    " \n",
    "        if not str(obj['H']).startswith('MM'):\n",
    "            return None\n",
    "        else:\n",
    "            if str(obj['H']).startswith('MM'):\n",
    "                if 'Hmm' in obj and 'HMM' in obj:\n",
    "                    obj['H'] = round(np.mean([float(obj['Hmm']), float(obj['HMM'])]),2)\n",
    "                    try:\n",
    "                        io.write_pickle(obj, fn)\n",
    "                        return 1\n",
    "                    except:\n",
    "                        return -1\n",
    "                else:\n",
    "                    obj['Hmm'] = estimator.get_param(fn, 'Hmm')\n",
    "                    obj['HMM'] = estimator.get_param(fn, 'HMM')\n",
    "                    obj['H'] = round(np.mean([float(obj['Hmm']), float(obj['HMM'])]),2)\n",
    "                    \n",
    "                    try:\n",
    "                        io.write_pickle(obj, fn)\n",
    "                        return 2\n",
    "                    except:\n",
    "                        return -2\n",
    "    else:\n",
    "        print(obj)\n",
    "        print(fn)\n",
    "    return 0\n",
    "\n",
    "def change_fit_graph_H(path, njobs=1):\n",
    "    exp = '/[!BAH]*_nodes/*_graph_*.gpickle'\n",
    "    change_H(path, exp, _change_fit_graph, njobs=njobs)\n",
    "    \n",
    "def change_synthetic_graph_H(path, njobs=1):\n",
    "    exp = '/BAH-*-Hmm*_nodes/*_graph_*.gpickle'\n",
    "    change_H(path, exp, _change_synthetic_graph, njobs=njobs)\n",
    "    \n",
    "def change_synthetic_evaluation_H(path, njobs=1):\n",
    "    exp = '/BAH-*-Hmm*_nodes/*_evaluation_*.pickle'\n",
    "    change_H(path, exp, _change_synthetic_eval, njobs=njobs)\n",
    "    \n",
    "def change_empirical_evaluation_H(path, njobs=1):\n",
    "    exp = '/[!BAH]*_nodes/*_evaluation_*.pickle'\n",
    "    change_H(path, exp, _change_empirical_eval, njobs=njobs)\n",
    "    \n",
    "def change_empirical_graph_H(path, njobs=1):\n",
    "    exp = '/[!BAH]*.gpickle'\n",
    "    change_H(path, exp, _change_empirical_graph, njobs=njobs)\n",
    "    \n",
    "def change_H(path, exp, callback, njobs=1):\n",
    "    files = glob.glob(path + exp, recursive=True)\n",
    "    print('{} files found.'.format(len(files)))\n",
    "    results = Parallel(n_jobs=njobs)(delayed(callback)(fn) for fn in files)\n",
    "    \n",
    "    results = np.array(results)\n",
    "    print('---')\n",
    "    print('{} changed (1).'.format(results[np.where(results==1)].shape[0]))\n",
    "    print('{} changed (2).'.format(results[np.where(results==2)].shape[0]))\n",
    "    print('{} already changed.'.format(results[np.where(results==None)].shape[0]))\n",
    "    print('{} NOT changed.'.format(results[np.where(results==0)].shape[0]))\n",
    "    print('{} error (1).'.format(results[np.where(results==-1)].shape[0]))\n",
    "    print('{} error (2).'.format(results[np.where(results==-2)].shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500 files found.\n",
      "---\n",
      "0 changed (1).\n",
      "0 changed (2).\n",
      "2500 already changed.\n",
      "0 NOT changed.\n",
      "0 error (1).\n",
      "0 error (2).\n"
     ]
    }
   ],
   "source": [
    "change_synthetic_graph_H('/bigdata/lespin/Network-Unbiased-Inference/results', 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500 files found.\n",
      "---\n",
      "0 changed (1).\n",
      "0 changed (2).\n",
      "2500 already changed.\n",
      "0 NOT changed.\n",
      "0 error (1).\n",
      "0 error (2).\n"
     ]
    }
   ],
   "source": [
    "change_synthetic_evaluation_H('/bigdata/lespin/Network-Unbiased-Inference/results', 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 files found.\n",
      "---\n",
      "0 changed (1).\n",
      "0 changed (2).\n",
      "500 already changed.\n",
      "0 NOT changed.\n",
      "0 error (1).\n",
      "0 error (2).\n"
     ]
    }
   ],
   "source": [
    "change_fit_graph_H('/bigdata/lespin/Network-Unbiased-Inference/results', 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 files found.\n",
      "---\n",
      "0 changed (1).\n",
      "0 changed (2).\n",
      "5 already changed.\n",
      "0 NOT changed.\n",
      "0 error (1).\n",
      "0 error (2).\n"
     ]
    }
   ],
   "source": [
    "change_empirical_graph_H('/ssd/lespin/code/Network-Inference/Discrimination-in-Relational-Classification/data', 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 files found.\n",
      "---\n",
      "0 changed (1).\n",
      "0 changed (2).\n",
      "500 already changed.\n",
      "0 NOT changed.\n",
      "0 error (1).\n",
      "0 error (2).\n"
     ]
    }
   ],
   "source": [
    "change_empirical_evaluation_H('/bigdata/lespin/Network-Unbiased-Inference/results', 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
