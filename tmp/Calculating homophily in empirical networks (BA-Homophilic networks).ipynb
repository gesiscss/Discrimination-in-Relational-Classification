{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import random as rd\n",
    "from scipy.optimize import fsolve\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from generate_homophilic_graph_asymmetric import homophilic_barabasi_albert_graph_assym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "# This function is useful if\n",
    "# you have an empirical in-group edges\n",
    "# and want to calculate numerically\n",
    "# the values of homophily.\n",
    "################################\n",
    "\n",
    "def numeric_solver(p):\n",
    "    h_aa,h_bb,ca,beta_a,beta_b = p\n",
    "    \n",
    "    fb = 1 - minority_fraction\n",
    "    fa = minority_fraction\n",
    "\n",
    "    M = maj_maj + maj_min + min_min\n",
    "    m_bb = maj_maj\n",
    "    m_ab = maj_min\n",
    "    m_aa = min_min\n",
    "\n",
    "    pbb = float(m_bb)/(m_aa+m_bb+m_ab)\n",
    "    paa = float(m_aa)/(m_aa+m_bb+m_ab)\n",
    "    pba = float(m_ab)/(m_aa+m_bb+m_ab)\n",
    "    pab = pba\n",
    "\n",
    "\n",
    "    h_ab = 1- h_aa\n",
    "    h_ba = 1- h_bb\n",
    "\n",
    "    A = (h_aa - h_ab)*(h_ba - h_bb)\n",
    "    B = ((2*h_bb - (1-fa) * h_ba)*(h_aa - h_ab) + (2*h_ab - fa*(2*h_aa - h_ab))*(h_ba - h_bb))\n",
    "    C = (2*h_bb*(2*h_ab - fa*(2*h_aa - h_ab)) - 2*fa*h_ab*(h_ba - h_bb) - 2*(1-fa)*h_ba * h_ab)\n",
    "    D = - 4*fa*h_ab*h_bb\n",
    "    \n",
    "    P = [A, B, C, D]\n",
    "\n",
    "    Z = fa / (1 - beta_a)\n",
    "    K = fb / (1 - beta_b)\n",
    "\n",
    "    #p_aa = (fa * h_aa *ba)/( h_aa *ba + h_ab *bb) # this is the exact result\n",
    "\n",
    "    #p_bb = (fb * h_bb *bb)/( h_bb *bb + h_ba *ba) # this is the exact result\n",
    "    \n",
    "    #p_ab = (fa*h_ab*bb) /(h_ab*bb +h_aa*ba) + (fb*h_ba*ba)/(h_ba*ba +h_bb*bb)\n",
    "    \n",
    "    #P_aa_analytic = float(p_aa)/(p_aa + p_bb + p_ab) # this is the exact result\n",
    "    #P_bb_analytic = float(p_bb)/(p_aa + p_bb + p_ab) # this is the exact result\n",
    "\n",
    "\n",
    "\n",
    "    return ( (pbb* ((fa * h_aa * Z)+ (fb*(1-h_bb)*Z) + (fa*(1-h_aa)*K)+(fb *h_bb*K) )) - (fb * h_bb * K ) , \n",
    "            \n",
    "            (paa* ((fa * h_aa * Z)+ (fb*(1-h_bb)*Z) + (fa*(1-h_aa)*K)+(fb *h_bb*K) ))  - (fa * h_aa * Z ) ,\n",
    "            \n",
    "            beta_a - float(fa*h_aa)/ (h_aa*ca + h_ab * (2 - ca)) - float(fb*h_ba)/(h_ba*ca + h_bb*(2-ca))  ,\n",
    "            \n",
    "            beta_b - float(fb*h_bb)/ (h_ba*ca + h_bb * (2 - ca)) - float(fa*h_ab)/(h_aa*ca + h_ab*(2-ca)) , \n",
    "            \n",
    "            ca - np.roots(P)[root_num] )\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_edges_empirical(G):\n",
    "    \n",
    "    maj_maj = 0\n",
    "    maj_min = 0\n",
    "    min_min = 0\n",
    "    # blue: majority (b) ; red:minority (a)\n",
    "    for e in G.edges():\n",
    "        n1,n2 = e\n",
    "        g1 = G.node[n1]['color']\n",
    "        g2 = G.node[n2]['color']\n",
    "        \n",
    "        if g1 == g2:\n",
    "            if g1 == 'blue':\n",
    "                maj_maj += 1\n",
    "            else:\n",
    "                min_min += 1\n",
    "        else:\n",
    "            maj_min += 1\n",
    "        \n",
    "    #print 'min_min , maj_min , maj_maj' , min_min , maj_min , maj_maj\n",
    "          \n",
    "    return min_min , maj_min , maj_maj\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measuring_empirical_homophily(maj_maj,maj_min,min_min,minority_fraction):\n",
    "    \n",
    "    '''\n",
    "    the estimation is largely depends on the initial values that are fed to the fsolver.\n",
    "    therefore it is important to initialize the fsolve functions with realist values to begin with.\n",
    "    Note that the exponent of the degree distribution (e) is related to the degree growth (beta)\n",
    "    as follows: e = float(1)/beta + 1. Therefore, if one can estimate the exponent of the \n",
    "    degree distribution for the minority and majority, it will help to initialze the values for beta.\n",
    "    \n",
    "    maj-maj etc are total number of majority to majority links. etc\n",
    "\n",
    "    '''\n",
    "\n",
    "    global root_num\n",
    "\n",
    "    for root_num in [0,1,2]:\n",
    "        \n",
    "        # h_aa,h_bb,ca,beta_a,beta_b\n",
    "        # these are initializations that you need to tune\n",
    "        \n",
    "        h_aa_anal,h_bb_anal,ca,beta_a,beta_b = fsolve(numeric_solver,(1,1,0.5,0.5,0.5)) \n",
    "        \n",
    "        print('estimations',h_aa_anal,h_bb_anal,ca, beta_a , beta_b)\n",
    "        e_min,e_maj = float(1)/beta_a + 1, float(1)/beta_b + 1\n",
    "        \n",
    "        if 0<ca and ca <2: #this is acceptable range for ca\n",
    "\n",
    "            return h_aa_anal, h_bb_anal , e_min , e_maj \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### values from the network function\n",
      "1.0 1.0\n",
      "estimations 1.6142020155010215 0.5330277634392193 10.264488025495526 0.9967761245418599 0.9957596705925416\n",
      "estimations 1.429377849566564 0.809738176392699 0.7213857199358904 0.7227558093394747 0.3743226456885339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ssd/lespin/virtualenv/python3.5/lib/python3.5/site-packages/scipy/optimize/minpack.py:162: RuntimeWarning: The iteration is not making good progress, as measured by the \n",
      "  improvement from the last five Jacobian evaluations.\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "N = 2000\n",
    "m = 2\n",
    "h_ab = 0. # haa = 0.7\n",
    "h_ba = 0. # hbb = 0.7\n",
    "minority_fraction = 0.2\n",
    "\n",
    "G = homophilic_barabasi_albert_graph_assym(N , m , minority_fraction, h_ab , h_ba)\n",
    "min_min , maj_min , maj_maj = calculate_edges_empirical(G)\n",
    "h_aa_prediction, h_bb_prediction , e_min , e_maj = measuring_empirical_homophily(maj_maj,maj_min,min_min,minority_fraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_aa_prediction 1.429377849566564 h_bb_prediction 0.809738176392699\n"
     ]
    }
   ],
   "source": [
    "print('h_aa_prediction',h_aa_prediction,'h_bb_prediction', h_bb_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] To ensure that the estimates are accurate, you can run maximum-likelihood estimate over all the values of homophiles and check which values give the closer estimates to paa and pbb, where pbb = float(m_bb)/(m_aa+m_bb+m_ab)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[2] Another solution is to give beta_a and beta_b as inputs instead of initial guess. In this way, the numerical solver will have easier time to predict the results since it has fewer parameters to predict. I haven't made the code yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center;\"><h1>Relational Classification</h1></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import networkx as nx\n",
    "from collections import Counter\n",
    "\n",
    "sys.path.append('../code')\n",
    "from org.gesis.network.network import Network\n",
    "\n",
    "def load_graph(fn):\n",
    "    return nx.read_gpickle(fn)\n",
    "\n",
    "def get_minority_fraction(G):\n",
    "    tmp = Counter([G.graph['group'][G.graph['labels'].index(G.node[n][G.graph['class']])] for n in G.nodes()])\n",
    "    return tmp['m'] / float(tmp['m']+tmp['M'])\n",
    "\n",
    "def get_edge_type_counts(G):\n",
    "    tmp = Counter(['{}{}'.format( G.graph['group'][G.graph['labels'].index(G.node[e[0]][G.graph['class']])], G.graph['group'][G.graph['labels'].index(G.node[e[1]][G.graph['class']])] ) for e in G.edges()])\n",
    "    min_min , maj_min , min_maj, maj_maj = tmp['mm'], tmp['Mm'] , tmp['mM'], tmp['MM']\n",
    "    return min_min , maj_min , min_maj, maj_maj\n",
    "\n",
    "def get_homophily_old_code(graph, smooth=1):\n",
    "\n",
    "    fm = get_minority_fraction(graph)\n",
    "    Emm, EMm, EmM, EMM = get_edge_type_counts(graph)\n",
    "\n",
    "    Emm += smooth\n",
    "    EMM += smooth\n",
    "    EMm += smooth\n",
    "    EmM += smooth\n",
    "\n",
    "    fM = 1 - fm\n",
    "    emm = float( Emm / (Emm + EMm + EmM + EMM) )\n",
    "    eMM = float( EMM / (Emm + EMm + EmM + EMM) )\n",
    "    \n",
    "    hmm = float(-2 * emm * fm * fM) / ((emm * (fm ** 2)) - (2 * emm * fm * fM) + (emm * (fM ** 2) - (fm ** 2)))\n",
    "    hMM = float(-2 * eMM * fM * fm) / ((eMM * (fM ** 2)) - (2 * eMM * fM * fm) + (eMM * (fm ** 2) - (fM ** 2)))\n",
    "\n",
    "    return hmm, hMM\n",
    "\n",
    "\n",
    "def estimate_homophily_empirical(graph, fm=None, EMM=None, EMm=None, EmM=None, Emm=None, gammaM_in=None, gammam_in=None, verbose=False):\n",
    "    \n",
    "    hmm = []\n",
    "    hMM = []\n",
    "    diff = []\n",
    "\n",
    "    if graph is not None and (fm is None or EMM is None or EMm is None or EmM is None or Emm is None):\n",
    "        Emm, EMm, EmM, EMM = get_edge_type_counts(graph)\n",
    "        fm = get_minority_fraction(graph)\n",
    "    elif graph is None and (fm is None or EMM is None or EMm is None or EmM is None or Emm is None):\n",
    "        raise Exception('Missing important parameters.')\n",
    "\n",
    "    E = EMM + EMm + EmM + Emm\n",
    "    min_min = Emm / E\n",
    "    maj_maj = EMM / E\n",
    "    min_maj = (EmM + EMm) / E\n",
    "    maj_min = (EmM + EMm) / E\n",
    "    fM = 1 - fm\n",
    "\n",
    "    # calculating ca for directed\n",
    "    K_m = min_min + maj_min\n",
    "    K_M = maj_maj + min_maj\n",
    "    K_all = K_m + K_M\n",
    "\n",
    "    cm = (K_m) / K_all\n",
    "    if verbose:\n",
    "        print(cm)\n",
    "\n",
    "    for h_mm_ in np.arange(0, 1.01, 0.01):\n",
    "        for h_MM_ in np.arange(0, 1.01, 0.01):\n",
    "\n",
    "            h_mm_analytical = h_mm_\n",
    "            h_MM_analytical = h_MM_\n",
    "\n",
    "            h_mM_analytical = 1 - h_mm_analytical\n",
    "            h_Mm_analytical = 1 - h_MM_analytical\n",
    "\n",
    "            if gammaM_in is None:\n",
    "                try:\n",
    "                    gamma_M = float(fM * h_MM_analytical) / ((h_Mm_analytical * cm) + (h_MM_analytical * (2 - cm))) + \n",
    "                              float(fm * h_mM_analytical) / ((h_mm_analytical * cm) + (h_mM_analytical * (2 - cm)))\n",
    "                except RuntimeWarning:\n",
    "                    if verbose:\n",
    "                        print('break 2')\n",
    "                    break\n",
    "            else:\n",
    "                gamma_M = gammaM_in\n",
    "\n",
    "\n",
    "            if gammam_in is None:\n",
    "                try:\n",
    "                    gamma_m = float(fm * h_mm_analytical) / ((h_mm_analytical * cm) + (h_mM_analytical * (2 - cm))) + \n",
    "                              float(fM * h_Mm_analytical) / ((h_Mm_analytical * cm) + (h_MM_analytical * (2 - cm)))\n",
    "                except RuntimeWarning:\n",
    "                    if verbose:\n",
    "                        print('break 1')\n",
    "                    break\n",
    "            else:\n",
    "                gamma_m = gammam_in\n",
    "\n",
    "\n",
    "            K = 1 - gamma_m\n",
    "            Z = 1 - gamma_M\n",
    "\n",
    "            if ((fm * h_mm_analytical * Z) + ((1 - fm) * (1 - h_mm_analytical) * K) == 0 or (fM * h_MM_analytical * K) + (fm * (1 - h_MM_analytical) * Z)) == 0:\n",
    "                break\n",
    "\n",
    "            pmm_analytical = float(fm * h_mm_analytical * Z) / ((fm * h_mm_analytical * Z) + ((1 - fm) * (1 - h_mm_analytical) * K))\n",
    "            pMM_analytical = float(fM * h_MM_analytical * K) / ((fM * h_MM_analytical * K) + (fm * (1 - h_MM_analytical) * Z))\n",
    "\n",
    "            if min_min + min_maj + maj_maj == 0:\n",
    "                # bipartite\n",
    "                raise NotImplementedError('This model does not support bipartite networks.')\n",
    "            else:\n",
    "                pmm_emp = float(min_min) / (min_min + min_maj)\n",
    "                pMM_emp = float(maj_maj) / (maj_maj + maj_min)\n",
    "\n",
    "            _diff = abs(pmm_emp - pmm_analytical) + abs(pMM_emp - pMM_analytical)\n",
    "            diff.append(_diff)\n",
    "            hmm.append(h_mm_analytical)\n",
    "            hMM.append(h_MM_analytical)\n",
    "\n",
    "            if verbose and _diff < 0.02:\n",
    "                print()\n",
    "                print('pmm_emp', pmm_emp, 'pmm_analytical', pmm_analytical)\n",
    "                print('pMM_emp', pMM_emp, 'pMM_analytical', pMM_analytical)\n",
    "                print('pMM_diff', abs(pmm_emp - pmm_analytical), 'pMM_diff', abs(pMM_emp - pMM_analytical) , 'diff' ,  _diff)\n",
    "                print('h_mm_analytical', h_mm_analytical, 'h_MM_analytical', h_MM_analytical, 'cm_analytical', cm)\n",
    "\n",
    "    best = np.argmin(diff)\n",
    "    return hMM[best], hmm[best]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Empirical Networks</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2351 6846 6267\n",
      "0.3252496433666191\n",
      "\n",
      "estimations 0.8717116172528777 0.5225589893609123 15.682269479085036 0.9969119165394742 0.9970111244449505\n",
      "estimations 0.7996384950832048 0.6045738354567473 0.7408737001794895 0.5609917813390208 0.46411225249673044\n",
      "h_mm_prediction 0.7996384950832048 h_MM_prediction 0.6045738354567473 average:  0.702106165269976\n",
      "\n",
      "hmm  0.7652598337554604 hMM 0.43831243100092065 h_avg 0.6017861323781906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ssd/lespin/virtualenv/python3.5/lib/python3.5/site-packages/scipy/optimize/minpack.py:162: RuntimeWarning: The iteration is not making good progress, as measured by the \n",
      "  improvement from the last five Jacobian evaluations.\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hmm  0.35000000000000003 hMM 0.37 h_avg 0.36\n"
     ]
    }
   ],
   "source": [
    "### Loading network\n",
    "G = load_graph('../data/Caltech36.gpickle')\n",
    "\n",
    "### computing minority fraction\n",
    "min_min , maj_min , min_maj, maj_maj = get_edge_type_counts(G)\n",
    "minority_fraction = get_minority_fraction(G)\n",
    "print(min_min , maj_min + min_maj, maj_maj)\n",
    "print(minority_fraction)\n",
    "print()\n",
    "\n",
    "### computing homophily MLE (Fariba's code: 2020-04-22, 5:01 PM)\n",
    "h_aa_prediction, h_bb_prediction , e_min , e_maj = measuring_empirical_homophily(maj_maj,maj_min+min_maj,min_min,minority_fraction)\n",
    "print('h_mm_prediction',h_aa_prediction,'h_MM_prediction', h_bb_prediction, 'average: ', np.mean([h_aa_prediction,h_bb_prediction]))\n",
    "print()\n",
    "\n",
    "### computing homophily estimation (Fariba's code: 2019-10-14, 1:49 PM)\n",
    "hm,hM = get_homophily_old_code(G)\n",
    "h = np.mean([hm,hM])\n",
    "print('hmm ',hm,'hMM', hM, 'h_avg', h)\n",
    "\n",
    "### computing homophily code for directed networks\n",
    "hMM,hmm = estimate_homophily_empirical(G)\n",
    "h = np.mean([hmm,hMM])\n",
    "print('hmm ',hmm,'hMM', hMM, 'h_avg', h)\n",
    "\n",
    "### Expected (from results submitted to ICWSM):\n",
    "# hmm 0.59\n",
    "# hMM 0.47\n",
    "# h   0.56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 39044 0\n",
      "0.39593544530783026\n",
      "\n",
      "estimations 0.6844546164104003 0.13273584637611838 1.3210542221835888 0.5365596039440803 0.18939032631881936\n",
      "h_mm_prediction 0.6844546164104003 h_MM_prediction 0.13273584637611838 average:  0.4085952313932593\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ssd/lespin/virtualenv/python3.5/lib/python3.5/site-packages/scipy/optimize/minpack.py:162: RuntimeWarning: The iteration is not making good progress, as measured by the \n",
      "  improvement from the last ten iterations.\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hmm  7.814356933193873e-05 hMM 3.3571716826090884e-05 h_avg 5.585764307901481e-05\n",
      "hmm  0.0 hMM 0.0 h_avg 0.0\n"
     ]
    }
   ],
   "source": [
    "### Loading network\n",
    "G = load_graph('../data/Escorts.gpickle')\n",
    "\n",
    "### computing minority fraction\n",
    "min_min , maj_min , min_maj, maj_maj = get_edge_type_counts(G)\n",
    "minority_fraction = get_minority_fraction(G)\n",
    "print(min_min , maj_min + min_maj, maj_maj)\n",
    "print(minority_fraction)\n",
    "print()\n",
    "\n",
    "### computing homophily MLE (Fariba's code: 2020-04-22, 5:01 PM)\n",
    "h_aa_prediction, h_bb_prediction , e_min , e_maj = measuring_empirical_homophily(maj_maj,maj_min+min_maj,min_min,minority_fraction)\n",
    "print('h_mm_prediction',h_aa_prediction,'h_MM_prediction', h_bb_prediction, 'average: ', np.mean([h_aa_prediction,h_bb_prediction]))\n",
    "print()\n",
    "\n",
    "### computing homophily estimation (Fariba's code: 2019-10-14, 1:49 PM)\n",
    "hm,hM = get_homophily_old_code(G)\n",
    "h = np.mean([hm,hM])\n",
    "print('hmm ',hm,'hMM', hM, 'h_avg', h)\n",
    "\n",
    "### computing homophily code for directed networks\n",
    "hMM,hmm = estimate_homophily_empirical(G)\n",
    "h = np.mean([hmm,hMM])\n",
    "print('hmm ',hmm,'hMM', hMM, 'h_avg', h)\n",
    "\n",
    "### Expected:\n",
    "# hmm 0.0\n",
    "# hMM 0.0\n",
    "# h   0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13689 25069 14968\n",
      "0.4924292297564187\n",
      "\n",
      "estimations 0.8399962951586148 0.5222384946530384 17.670305437019255 0.9907578470078275 0.9944170669110332\n",
      "estimations 0.7011971177850213 0.7039269542804274 0.9811443540581335 0.4964128363609678 0.5031387724402454\n",
      "h_mm_prediction 0.7011971177850213 h_MM_prediction 0.7039269542804274 average:  0.7025620360327243\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ssd/lespin/virtualenv/python3.5/lib/python3.5/site-packages/scipy/optimize/minpack.py:162: RuntimeWarning: The iteration is not making good progress, as measured by the \n",
      "  improvement from the last five Jacobian evaluations.\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "/ssd/lespin/virtualenv/python3.5/lib/python3.5/site-packages/scipy/optimize/minpack.py:162: RuntimeWarning: The iteration is not making good progress, as measured by the \n",
      "  improvement from the last ten iterations.\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hmm  0.5253805830077487 hMM 0.5407055778616089 h_avg 0.5330430804346789\n",
      "hmm  0.35000000000000003 hMM 0.37 h_avg 0.36\n"
     ]
    }
   ],
   "source": [
    "### Loading network\n",
    "G = load_graph('../data/Swarthmore42.gpickle')\n",
    "\n",
    "### computing minority fraction\n",
    "min_min , maj_min , min_maj, maj_maj = get_edge_type_counts(G)\n",
    "minority_fraction = get_minority_fraction(G)\n",
    "print(min_min , maj_min + min_maj, maj_maj)\n",
    "print(minority_fraction)\n",
    "print()\n",
    "\n",
    "### computing homophily MLE (Fariba's code: 2020-04-22, 5:01 PM)\n",
    "h_aa_prediction, h_bb_prediction , e_min , e_maj = measuring_empirical_homophily(maj_maj,maj_min+min_maj,min_min,minority_fraction)\n",
    "print('h_mm_prediction',h_aa_prediction,'h_MM_prediction', h_bb_prediction, 'average: ', np.mean([h_aa_prediction,h_bb_prediction]))\n",
    "print()\n",
    "\n",
    "### computing homophily estimation (Fariba's code: 2019-10-14, 1:49 PM)\n",
    "hm,hM = get_homophily_old_code(G)\n",
    "h = np.mean([hm,hM])\n",
    "print('hmm ',hm,'hMM', hM, 'h_avg', h)\n",
    "\n",
    "### computing homophily code for directed networks\n",
    "hMM,hmm = estimate_homophily_empirical(G)\n",
    "h = np.mean([hmm,hMM])\n",
    "print('hmm ',hmm,'hMM', hMM, 'h_avg', h)\n",
    "\n",
    "### Expected (from results submitted to ICWSM):\n",
    "# hmm 0.53\n",
    "# hMM 0.53\n",
    "# h   0.53"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1798 8528 5271\n",
      "0.40410557184750734\n",
      "\n",
      "estimations 0.6330283491590013 0.525339514201356 14.639405394766781 0.9916335507247485 0.9948500847449296\n",
      "estimations 0.7298584914929618 0.6860597171769255 0.8241639501574772 0.4628485822968569 0.5081503962443819\n",
      "h_mm_prediction 0.7298584914929618 h_MM_prediction 0.6860597171769255 average:  0.7079591043349436\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ssd/lespin/virtualenv/python3.5/lib/python3.5/site-packages/scipy/optimize/minpack.py:162: RuntimeWarning: The iteration is not making good progress, as measured by the \n",
      "  improvement from the last five Jacobian evaluations.\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "/ssd/lespin/virtualenv/python3.5/lib/python3.5/site-packages/scipy/optimize/minpack.py:162: RuntimeWarning: The iteration is not making good progress, as measured by the \n",
      "  improvement from the last ten iterations.\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hmm  0.3491504266836932 hMM 0.4749560745170153 h_avg 0.41205325060035425\n",
      "hmm  0.21 hMM 0.33 h_avg 0.27\n"
     ]
    }
   ],
   "source": [
    "### Loading network\n",
    "G = load_graph('../data/USF512009.gpickle')\n",
    "\n",
    "### computing minority fraction\n",
    "min_min , maj_min , min_maj, maj_maj = get_edge_type_counts(G)\n",
    "minority_fraction = get_minority_fraction(G)\n",
    "print(min_min , maj_min + min_maj, maj_maj)\n",
    "print(minority_fraction)\n",
    "print()\n",
    "\n",
    "### computing homophily MLE (Fariba's code: 2020-04-22, 5:01 PM)\n",
    "h_aa_prediction, h_bb_prediction , e_min , e_maj = measuring_empirical_homophily(maj_maj,maj_min+min_maj,min_min,minority_fraction)\n",
    "print('h_mm_prediction',h_aa_prediction,'h_MM_prediction', h_bb_prediction, 'average: ', np.mean([h_aa_prediction,h_bb_prediction]))\n",
    "print()\n",
    "\n",
    "### computing homophily estimation (Fariba's code: 2019-10-14, 1:49 PM)\n",
    "hm,hM = get_homophily_old_code(G)\n",
    "h = np.mean([hm,hM])\n",
    "print('hmm ',hm,'hMM', hM, 'h_avg', h)\n",
    "\n",
    "### computing homophily code for directed networks\n",
    "hMM,hmm = estimate_homophily_empirical(G)\n",
    "h = np.mean([hmm,hMM])\n",
    "print('hmm ',hmm,'hMM', hMM, 'h_avg', h)\n",
    "\n",
    "### Expected (from results submitted to ICWSM):\n",
    "# hmm 0.39\n",
    "# hMM 0.45\n",
    "# h   0.45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125 584 2434\n",
      "0.15337711069418386\n",
      "\n",
      "estimations 1.019075560770563 0.546961899568215 7.344023058188957 0.997784106765801 0.9981404867052277\n",
      "estimations 0.9271866657631672 0.6730628160221609 0.34132533483820254 0.5506424662098885 0.4895786936977739\n",
      "h_mm_prediction 0.9271866657631672 h_MM_prediction 0.6730628160221609 average:  0.800124740892664\n",
      "\n",
      "hmm  2.4279760725082284 hMM 0.5826041849704131 h_avg 1.5052901287393208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ssd/lespin/virtualenv/python3.5/lib/python3.5/site-packages/scipy/optimize/minpack.py:162: RuntimeWarning: The iteration is not making good progress, as measured by the \n",
      "  improvement from the last five Jacobian evaluations.\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hmm  0.5 hMM 0.46 h_avg 0.48\n"
     ]
    }
   ],
   "source": [
    "### Loading network\n",
    "G = load_graph('../data/Wikipedia.gpickle')\n",
    "\n",
    "### computing minority fraction\n",
    "min_min , maj_min , min_maj, maj_maj = get_edge_type_counts(G)\n",
    "minority_fraction = get_minority_fraction(G)\n",
    "print(min_min , maj_min + min_maj, maj_maj)\n",
    "print(minority_fraction)\n",
    "print()\n",
    "\n",
    "### computing homophily MLE (Fariba's code: 2020-04-22, 5:01 PM)\n",
    "h_aa_prediction, h_bb_prediction , e_min , e_maj = measuring_empirical_homophily(maj_maj,maj_min+min_maj,min_min,minority_fraction)\n",
    "print('h_mm_prediction',h_aa_prediction,'h_MM_prediction', h_bb_prediction, 'average: ', np.mean([h_aa_prediction,h_bb_prediction]))\n",
    "print()\n",
    "\n",
    "### computing homophily estimation (Fariba's code: 2019-10-14, 1:49 PM)\n",
    "hm,hM = get_homophily_old_code(G)\n",
    "h = np.mean([hm,hM])\n",
    "print('hmm ',hm,'hMM', hM, 'h_avg', h)\n",
    "\n",
    "### computing homophily code for directed networks\n",
    "hMM,hmm = estimate_homophily_empirical(G)\n",
    "h = np.mean([hmm,hMM])\n",
    "print('hmm ',hmm,'hMM', hMM, 'h_avg', h)\n",
    "\n",
    "### Expected (from results submitted to ICWSM):\n",
    "# hmm 0.70\n",
    "# hMM 0.60\n",
    "# h   0.60"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
